@book{DeJong:2016:ECU:3027779,
 author = {De Jong, Kenneth A.},
 title = {Evolutionary Computation: A Unified Approach},
 year = {2016},
 isbn = {0262529602, 9780262529600},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
}

@article{Al-Sahaf:2019,
author = {Harith Al-Sahaf and Ying Bi and Qi Chen and Andrew Lensen and Yi Mei and Yanan Sun and Binh Tran and Bing Xue and Mengjie Zhang},
title = {A survey on evolutionary machine learning},
journal = {Journal of the Royal Society of New Zealand},
volume = {49},
number = {2},
pages = {205-228},
year  = {2019},
publisher = {Taylor & Francis},
doi = {10.1080/03036758.2019.1609052}}

@Article{Rumelhart1986,
author={Rumelhart, David E.
and Hinton, Geoffrey E.
and Williams, Ronald J.},
title={Learning representations by back-propagating errors},
journal={Nature},
year={1986},
volume={323},
number={6088},
pages={533-536},
abstract={We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal 'hidden' units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.},
issn={1476-4687},
doi={10.1038/323533a0},
url={https://doi.org/10.1038/323533a0}
}

@article{NEAT,
  title={Evolving Neural Networks through Augmenting Topologies},
  author={Kenneth O. Stanley and Risto Miikkulainen},
  journal={Evolutionary Computation},
  year={2001},
  volume={10},
  pages={99-127}
}

@Article{Stanley2019,
author={Stanley, Kenneth O.
and Clune, Jeff
and Lehman, Joel
and Miikkulainen, Risto},
title={Designing neural networks through neuroevolution},
journal={Nature Machine Intelligence},
year={2019},
volume={1},
number={1},
pages={24-35},
abstract={Much of recent machine learning has focused on deep learning, in which neural network weights are trained through variants of stochastic gradient descent. An alternative approach comes from the field of neuroevolution, which harnesses evolutionary algorithms to optimize neural networks, inspired by the fact that natural brains themselves are the products of an evolutionary process. Neuroevolution enables important capabilities that are typically unavailable to gradient-based approaches, including learning neural network building blocks (for example activation functions), hyperparameters, architectures and even the algorithms for learning themselves. Neuroevolution also differs from deep learning (and deep reinforcement learning) by maintaining a population of solutions during search, enabling extreme exploration and massive parallelization. Finally, because neuroevolution research has (until recently) developed largely in isolation from gradient-based neural network research, it has developed many unique and effective techniques that should be effective in other machine learning areas too. This Review looks at several key aspects of modern neuroevolution, including large-scale computing, the benefits of novelty and diversity, the power of indirect encoding, and the field's contributions to meta-learning and architecture search. Our hope is to inspire renewed interest in the field as it meets the potential of the increasing computation available today, to highlight how many of its ideas can provide an exciting resource for inspiration and hybridization to the deep learning, deep reinforcement learning and machine learning communities, and to explain how neuroevolution could prove to be a critical tool in the long-term pursuit of artificial general intelligence.},
issn={2522-5839},
doi={10.1038/s42256-018-0006-z},
url={https://doi.org/10.1038/s42256-018-0006-z}
}

@ARTICLE{2019arXiv190206827L,
       author = {{Liang}, Jason and {Meyerson}, Elliot and {Hodjat}, Babak and
         {Fink}, Dan and {Mutch}, Karl and {Miikkulainen}, Risto},
        title = "{Evolutionary Neural AutoML for Deep Learning}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Neural and Evolutionary Computing},
         year = "2019",
        month = "Feb",
          eid = {arXiv:1902.06827},
        pages = {arXiv:1902.06827},
archivePrefix = {arXiv},
       eprint = {1902.06827},
 primaryClass = {cs.NE},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190206827L},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{DBLP:journals/corr/MiikkulainenLMR17,
  author    = {Risto Miikkulainen and
               Jason Zhi Liang and
               Elliot Meyerson and
               Aditya Rawal and
               Daniel Fink and
               Olivier Francon and
               Bala Raju and
               Hormoz Shahrzad and
               Arshak Navruzyan and
               Nigel Duffy and
               Babak Hodjat},
  title     = {Evolving Deep Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1703.00548},
  year      = {2017},
  url       = {http://arxiv.org/abs/1703.00548},
  archivePrefix = {arXiv},
  eprint    = {1703.00548},
  timestamp = {Mon, 13 Aug 2018 16:47:55 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/MiikkulainenLMR17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Moriarty1997FormingNN,
  title={Forming Neural Networks Through Efficient and Adaptive Coevolution},
  author={David E. Moriarty and Risto Miikkulainen},
  journal={Evolutionary Computation},
  year={1997},
  volume={5},
  pages={373-399}
}

@inproceedings{Gomez:1999:SNC:1624312.1624411,
 author = {Gomez, Faustino J. and Miikkulainen, Risto},
 title = {Solving non-Markovian Control Tasks with Neuroevolution},
 booktitle = {Proceedings of the 16th International Joint Conference on Artificial Intelligence - Volume 2},
 series = {IJCAI'99},
 year = {1999},
 location = {Stockholm, Sweden},
 pages = {1356--1361},
 numpages = {6},
 url = {http://dl.acm.org/citation.cfm?id=1624312.1624411},
 acmid = {1624411},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
} 

@Article{gomez:jmlr08,
title={Accelerated Neural Evolution through Cooperatively Coevolved Synapses},
author={Faustino Gomez and Juergen Schmidhuber and Risto Miikkulainen},
journal={Journal of Machine Learning Research},
pages={937-965},
url="http://nn.cs.utexas.edu/?gomez:jmlr08",
year={2008}
}



@article{DBLP:journals/corr/ChenFLVGDZ15,
  author    = {Xinlei Chen and
               Hao Fang and
               Tsung{-}Yi Lin and
               Ramakrishna Vedantam and
               Saurabh Gupta and
               Piotr Doll{\'{a}}r and
               C. Lawrence Zitnick},
  title     = {Microsoft {COCO} Captions: Data Collection and Evaluation Server},
  journal   = {CoRR},
  volume    = {abs/1504.00325},
  year      = {2015},
  url       = {http://arxiv.org/abs/1504.00325},
  archivePrefix = {arXiv},
  eprint    = {1504.00325},
  timestamp = {Mon, 04 Mar 2019 08:31:20 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/ChenFLVGDZ15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{CIFAR-10,
title= {CIFAR-10 (Canadian Institute for Advanced Research)},
journal= {},
author= {Alex Krizhevsky and Vinod Nair and Geoffrey Hinton},
year= {},
url= {http://www.cs.toronto.edu/~kriz/cifar.html},
abstract= {The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. 

The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. },
keywords= {Dataset},
terms= {}
}

@inproceedings{Fernando:2016:CED:2908812.2908890,
 author = {Fernando, Chrisantha and Banarse, Dylan and Reynolds, Malcolm and Besse, Frederic and Pfau, David and Jaderberg, Max and Lanctot, Marc and Wierstra, Daan},
 title = {Convolution by Evolution: Differentiable Pattern Producing Networks},
 booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference 2016},
 series = {GECCO '16},
 year = {2016},
 isbn = {978-1-4503-4206-3},
 location = {Denver, Colorado, USA},
 pages = {109--116},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/2908812.2908890},
 doi = {10.1145/2908812.2908890},
 acmid = {2908890},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {CPPNs, MNIST, compositional pattern producing networks, denoising autoencoder},
} 

@misc{ha2016hypernetworks,
    title={HyperNetworks},
    author={David Ha and Andrew Dai and Quoc V. Le},
    year={2016},
    eprint={1609.09106},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{vanSteenkiste:2016:WEN:2908812.2908905,
 author = {van Steenkiste, Sjoerd and Koutn\'{\i}k, Jan and Driessens, Kurt and Schmidhuber, J\"{u}rgen},
 title = {A Wavelet-based Encoding for Neuroevolution},
 booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference 2016},
 series = {GECCO '16},
 year = {2016},
 isbn = {978-1-4503-4206-3},
 location = {Denver, Colorado, USA},
 pages = {517--524},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/2908812.2908905},
 doi = {10.1145/2908812.2908905},
 acmid = {2908905},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {gene-locality, indirect encoding, neuroevolution, wavelets},
} 

@inproceedings{Koutnik:2010:ENN:1830483.1830596,
 author = {Koutnik, Jan and Gomez, Faustino and Schmidhuber, J\"{u}rgen},
 title = {Evolving Neural Networks in Compressed Weight Space},
 booktitle = {Proceedings of the 12th Annual Conference on Genetic and Evolutionary Computation},
 series = {GECCO '10},
 year = {2010},
 isbn = {978-1-4503-0072-8},
 location = {Portland, Oregon, USA},
 pages = {619--626},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1830483.1830596},
 doi = {10.1145/1830483.1830596},
 acmid = {1830596},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {evolutionary algorithms, indirect encoding, neuroevolution, recurrent neural networks},
} 

@article{hyperneat,
author = {Stanley, Kenneth and D'Ambrosio, David and Gauci, Jason},
year = {2009},
month = {02},
pages = {185-212},
title = {A Hypercube-Based Encoding for Evolving Large-Scale Neural Networks},
volume = {15},
journal = {Artificial life},
doi = {10.1162/artl.2009.15.2.15202}
}

@article{PhysRevLett.102.152001,
  title = {Measurement of the Top-Quark Mass with Dilepton Events Selected Using Neuroevolution at CDF},
  author = {Aaltonen, T. et al.},
  collaboration = {CDF Collaboration},
  journal = {Phys. Rev. Lett.},
  volume = {102},
  issue = {15},
  pages = {152001},
  numpages = {8},
  year = {2009},
  month = {Apr},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.102.152001},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.102.152001}
}

@inproceedings{Verbancsics:2011:CCE:2001576.2001776,
 author = {Verbancsics, Phillip and Stanley, Kenneth O.},
 title = {Constraining Connectivity to Encourage Modularity in HyperNEAT},
 booktitle = {Proceedings of the 13th Annual Conference on Genetic and Evolutionary Computation},
 series = {GECCO '11},
 year = {2011},
 isbn = {978-1-4503-0557-0},
 location = {Dublin, Ireland},
 pages = {1483--1490},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/2001576.2001776},
 doi = {10.1145/2001576.2001776},
 acmid = {2001776},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {artificial neural networks, generative and developmental systems, hyperneat, modularity},
} 

@INPROCEEDINGS{4983289,
author={J. {Clune} and B. E. {Beckmann} and C. {Ofria} and R. T. {Pennock}},
booktitle={2009 IEEE Congress on Evolutionary Computation},
title={Evolving coordinated quadruped gaits with the HyperNEAT generative encoding},
year={2009},
volume={},
number={},
pages={2764-2771},
keywords={control engineering computing;evolutionary computation;legged locomotion;path planning;coordinated quadruped gaits;HyperNEAT generative encoding;legged robots;mobility tasks;rough terrain navigation;control software design;evolutionary algorithms;problem simplification;Encoding;Robot kinematics;Legged locomotion;Mobile robots;Navigation;Evolutionary computation;Neural networks;Genetics;Leg;Control systems},
doi={10.1109/CEC.2009.4983289},
ISSN={},
month={May},}

@article{hausknecht:tciaig13,
title={A Neuroevolution Approach to General Atari Game Playing},
author={Matthew Hausknecht and Joel Lehman and Risto Miikkulainen and Peter Stone},
journal={IEEE Transactions on Computational Intelligence and AI in Games},
url="http://nn.cs.utexas.edu/?hausknecht:tciaig14",
year={2013}
}

@article{DBLP:journals/corr/ZophL16,
  author    = {Barret Zoph and
               Quoc V. Le},
  title     = {Neural Architecture Search with Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1611.01578},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.01578},
  archivePrefix = {arXiv},
  eprint    = {1611.01578},
  timestamp = {Mon, 13 Aug 2018 16:46:24 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/ZophL16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@InCollection{boulic:91,
  author = 	 {R. Boulic and O. Renault},
  title = 	 {3D Hierarchies for Animation},
  booktitle = 	 {New Trends in Animation and Visualization},
  publisher =    {John Wiley {\&} Sons ltd.},
  year = 	 {1991},
  editor = 	 {Nadia Magnenat-Thalmann and Daniel Thalmann}
}

@InCollection{smith:99,
  author = 	 {A. Smith and B. Jones},
  title = 	 {On the Complexity of Computing},
  booktitle = 	 {Advances in Computer Science},
  pages = 	 {555--566},
  publisher =    {Publishing Press},
  year = 	 {1999},
  editor = 	 {A. B. Smith-Jones}
}
